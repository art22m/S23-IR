{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Measure and improve\n",
    "Murashko Artem SD20-01 | ar.murashko@innopolis.university\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know that search engine's quality improved (or at least haven't deteriorated) because of our changes?\n",
    "\n",
    "All we need is a way to ***evaluate*** our search engine. We will consider some of the popular evaluation techniques:\n",
    "\n",
    "1. Mean Average Precision\n",
    "2. 11-Point Interpolated Average\n",
    "3. Normalized Discounted Cumulative Gain (NDCG)\n",
    "4. pFound\n",
    "\n",
    "<!--We will apply them in the context of ranking with language models and will compare two ways of smoothing: additive and Jelinek-Mercer smoothing.\n",
    "-->\n",
    "\n",
    "It's best to go through the [book](https://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf) *chapter 8*, concretely, *8.4* to understand the key concepts of this lab. Here we will only present some excerpts from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. [10] Mean Average Precision\n",
    "\n",
    "The most standard metric among the TREC community is *Mean Average Precision* *(MAP)*, which provides a single-figure measure of quality across recall levels. Among evaluation measures, MAP has been shown to have especially good discrimination and stability. For a single information need, Average Precision is the average of the precision value obtained for the set of top $k$ documents existing\n",
    "after each relevant document is retrieved, and this value is then averaged over information needs (queries). \n",
    "Assume we have a bucket $Q$ of queries $q_j\\in Q$.\n",
    "If the set of **relevant documents** for an information need (query) $q_j$ is {d<sub>1</sub>, . . . d<sub>m<sub>j</sub></sub>} and R<sub>jk</sub> is the set of ranked retrieval results from the top result until you get to document d<sub>k</sub>, then\n",
    "\n",
    "![](https://i.imgur.com/EGQMHVq.png)\n",
    "\n",
    "Implement this metric in the `mean_avg_precision` function.\n",
    "\n",
    "**NB** Don't make the name of [the metric confuse you](https://towardsdatascience.com/breaking-down-mean-average-precision-map-ae462f623a52). *Average Precision* is the term, which corresponds to the area under precision-recall curve. It's computation is tricky. We suggest to start with implementing [$AveP$](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Average_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_avg_precision(search_results, relevance):\n",
    "    AP_sum = 0\n",
    "    for id, search_result in enumerate(search_results):\n",
    "        # Average Precision\n",
    "        AP = 0\n",
    "        \n",
    "        # Save all relevant docs id into set\n",
    "        relevant_ids = set([r[0] for r in relevance[id + 1]])\n",
    "        \n",
    "        # Calculate AP for the current search result\n",
    "        relevant_count = 0\n",
    "        total_count = 0\n",
    "        for doc_id in search_result:\n",
    "            is_relevant = 1 if doc_id in relevant_ids else 0\n",
    "\n",
    "            relevant_count += is_relevant\n",
    "            total_count += 1                \n",
    "            \n",
    "            # If current doc is not relevant, then is_relevant will be zero,\n",
    "            # so we will add zero to the AP. Otherwise, we will add precision\n",
    "            # of relevant document.\n",
    "            AP += relevant_count / total_count * is_relevant\n",
    "        \n",
    "        # To get actual average precision, we need to divide our sum of precisions\n",
    "        # of relevant docs by the number of relevant docs (e.g. the length of the set).\n",
    "        AP /= len(relevant_ids)\n",
    "\n",
    "        AP_sum += AP\n",
    "        \n",
    "    MAP = AP_sum / len(search_results)\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map_test 0.6464285714285715\n"
     ]
    }
   ],
   "source": [
    "test_relevance = {1: [(9, 1), (1, 2), (8, 3)], 2: [(5, 1), (9, 2), (6, 3)], \n",
    "                  3: [(9, 1), (4, 2), (6, 3)], 4: [(10, 1), (4, 2), (7, 3)], \n",
    "                  5: [(4, 1), (2, 2), (8, 3)], 6: [(2, 1), (9, 2), (4, 3)], \n",
    "                  7: [(1, 1), (2, 2), (3, 3)], 8: [(3, 1), (2, 2), (6, 3)], \n",
    "                  9: [(1, 1), (4, 2), (3, 3)], 10: [(10, 1), (7, 2), (8, 3)]}\n",
    "test_results = [[4, 5, 3, 6, 1, 2, 8, 9, 10, 7], [7, 5, 6, 3, 1, 8, 9, 4, 2, 10], \n",
    "                [8, 3, 4, 5, 9, 6, 1, 10, 2, 7], [4, 5, 7, 3, 6, 10, 1, 9, 2, 8], \n",
    "                [4, 8, 3, 5, 6, 7, 2, 1, 10, 9], [9, 7, 6, 5, 2, 4, 10, 1, 3, 8], \n",
    "                [3, 1, 5, 2, 10, 6, 7, 9, 8, 4], [9, 2, 4, 10, 8, 3, 7, 6, 1, 5], \n",
    "                [3, 4, 6, 1, 5, 10, 7, 2, 8, 9], [8, 10, 4, 1, 3, 7, 5, 6, 9, 2]]\n",
    "\n",
    "\n",
    "map_test = mean_avg_precision(test_results, test_relevance)\n",
    "print(\"map_test\", map_test)\n",
    "assert np.isclose(map_test, 0.646, atol=1e-03)\n",
    "assert mean_avg_precision(test_results[:5], test_relevance) > mean_avg_precision(test_results[5:10], test_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. [15] 11-Point Interpolated Average\n",
    "\n",
    "In a ranked retrieval context, appropriate sets of retrieved documents are naturally given by the top k retrieved documents. For each such set, precision and recall values can be plotted to give a precision-recall curve, such as this one (blue line):\n",
    "\n",
    "![](https://i.imgur.com/QnvDLAJ.png)\n",
    "\n",
    "Precision-recall curves have a distinctive saw-tooth shape: if the *(k + 1)<sup>th</sup>* document retrieved is nonrelevant then recall is the same as for the top k documents, but precision has dropped. If it is relevant, then both precision and recall increase, and the curve jags up and to the right.\n",
    "\n",
    "It is often useful to remove these jiggles and the standard way to do this is with an *interpolated precision*: the interpolated precision *p<sub>interp</sub>* at a certain recall level *r* is defined as the highest precision found for any recall level *r′* ≥ *r*:\n",
    "\n",
    "![](https://i.imgur.com/GMl2rQw.png)\n",
    "\n",
    "The justification is that almost anyone would be prepared to look at a few more documents if it would increase the percentage of the viewed set that were relevant (that is, if the precision of the larger set is higher). Interpolated precision is shown by a red line in the figure above.\n",
    "\n",
    "Examining this information for a single query may be useful, but usually we are more interested in a composite metrics, which will score over all test queries. The traditional way of doing this is the *11-point interpolated average*. For each information need, the interpolated precision is measured at the 11 recall levels of 0.0, 0.1, 0.2, . . . , 1.0. Then we average interpolated precision over all queries in the test collection and plot, like here:\n",
    "\n",
    "![](https://i.imgur.com/6wDmtp2.png)\n",
    "\n",
    "\n",
    "Plotting a number of such graphs for different versions of search engine on the same plot helps to compare their performance.\n",
    "\n",
    "You need to incorporate this logic into `eleven_points_interpolated_avg` function. Break it down to subfuctions as it seems necessary to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(precisions, recalls):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    \n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.show()\n",
    "\n",
    "def interpolate(precisions, recalls):\n",
    "    result = []\n",
    "    # Iterate through each recall out of eleven and find its precision\n",
    "    # using formula : pr_inter(recall) = max precisions(r), r >= recall\n",
    "    for recall in np.arange(start=0.0, stop=1.1, step=0.1):\n",
    "        max_precision = 0\n",
    "        for i in range(len(recalls)):\n",
    "            if recalls[i] >= recall:    \n",
    "                max_precision = max(max_precision, precisions[i])\n",
    "        \n",
    "        result.append(max_precision)\n",
    "    \n",
    "    return np.array(result)\n",
    "\n",
    "def eleven_points_interpolated_avg(search_results, relevance, plot=True):\n",
    "    interpolated_precisions = []\n",
    "    for id, search_result in enumerate(search_results):\n",
    "        # Save all relevant docs id into set\n",
    "        relevant_ids = set([r[0] for r in relevance[id + 1]])\n",
    "        total_relevants = len(relevant_ids)\n",
    "        \n",
    "        relevant_count = 0\n",
    "        current_count = 0\n",
    "        \n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        for doc_id in search_result:\n",
    "            relevant_count += 1 if doc_id in relevant_ids else 0\n",
    "            current_count += 1                \n",
    "            \n",
    "            precisions.append(relevant_count / current_count)\n",
    "            recalls.append(relevant_count / total_relevants)\n",
    "        \n",
    "        interpolated_precision = interpolate(precisions, recalls)\n",
    "        interpolated_precisions.append(interpolated_precision)\n",
    "    \n",
    "    interpolated_precisions = np.array(interpolated_precisions)\n",
    "    interpolated_precisions_avg = []\n",
    "    \n",
    "    # Iterate through each point out of eleven and calculate avg precision in it\n",
    "    for i in range(11):\n",
    "        # Sum all the i'th precisions and divide by the number of search results (= len(interpolated_precisions))\n",
    "        precision_average = interpolated_precisions[:,i].sum() / len(interpolated_precisions)\n",
    "        interpolated_precisions_avg.append(precision_average)\n",
    "\n",
    "    if plot:\n",
    "        plot_curve(interpolated_precisions_avg, np.arange(start=0.0, stop=1.1, step=0.1))\n",
    "        \n",
    "    return interpolated_precisions_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1.Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eleven_test = eleven_points_interpolated_avg(test_results, test_relevance, plot=True)\n",
    "assert all(eleven_test[k] >= eleven_test[k+1] for k in range(len(eleven_test)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. [10] Normalized Discounted Cumulative Gain\n",
    "\n",
    "NDCG metric is designed for situations of non-binary notions of relevance. It is evaluated over some number $k$ of top search results (in our case we will evaluate over the whole dataset, since it is small). \n",
    "\n",
    "For a set of queries $Q$, let $R(j,d)$ be the relevance score assessors gave to document $d$ for query $j$. Then,\n",
    "\n",
    "![](https://i.imgur.com/LLogCYa.png)\n",
    "\n",
    "where $Z_{kj}$ is a normalization factor calculated to make it so that a perfect ranking’s NDCG at $k$ for query $j$ is 1. In other words, we divide calculated DCG score by ideal DCG score. \n",
    "\n",
    "Implement this metric in `NDCG` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Discounted Cumulative Gain\n",
    "def DCG(relevance):\n",
    "    DCG = 0\n",
    "    for i, r in enumerate(relevance, 1):            \n",
    "        DCG += (2 ** r - 1) / np.log2(i + 1)\n",
    "        \n",
    "    return DCG\n",
    "\n",
    "# Normalized Discounted Cumulative Gain\n",
    "def NDCG(search_results, relevance):\n",
    "    result = 0\n",
    "    for id, search_result in enumerate(search_results, 1): \n",
    "        # We need to calculate the inverted relevance to make scores\n",
    "        # 0 - not relevant, 1 - least relevant, 4 - most relevant\n",
    "        # Thus, make the default values equal to zero and subtract from 5\n",
    "        # the scores of relevant docs.\n",
    "        inverted_relevance = [0] * len(search_result)\n",
    "        for i, r in relevance[id]:\n",
    "            inverted_relevance[i - 1] = 5 - r\n",
    "        \n",
    "        # Arrange the relevance in the order of documents appearance in the search\n",
    "        relevance_in_order = [inverted_relevance[doc_id - 1] for doc_id in search_result]\n",
    "        \n",
    "        # Calculate Real Discounted Cumulative and Ideal Discounted Cumulative gains\n",
    "        real_DCG = DCG(relevance_in_order)\n",
    "        ideal_DCG = DCG(sorted(relevance_in_order, reverse=True))\n",
    "        \n",
    "        # Sum the ratios of real DCG score by ideal DCG scores\n",
    "        result += real_DCG / ideal_DCG\n",
    "\n",
    "    return result / len(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg_test 0.6409675295633275\n"
     ]
    }
   ],
   "source": [
    "# ndcg_test = testNDCG(test_results, test_relevance)\n",
    "# print(\"---\")\n",
    "ndcg_test = NDCG(test_results, test_relevance)\n",
    "print(\"ndcg_test\", ndcg_test)\n",
    "assert np.isclose(ndcg_test, 0.640, atol=1e-03)\n",
    "assert NDCG(test_results[:5], test_relevance) < NDCG(test_results[5:10], test_relevance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. [15] pFound ## \n",
    "**pFound** -- ranking metric invented in [Yandex](http://romip.ru/romip2009/15_yandex.pdf). This metric models user behaviour when looking at the search engine representation page (SERP). Metric assumes a user is inspecting a list from the top to the bottom. There are 2 global parameters, controlling behaviour:\n",
    "- `pBreak` -- how probable, that the user will become tired and just quit at this position (`0.15` by default).\n",
    "- `pRel` -- how probable the user will click the document if this document is relevant (`0.4` by default for a relevan document, `0` is given to irrelevant).\n",
    "\n",
    "Then, to compute pFound for the exact page we do:\n",
    "\n",
    "$pLook_i = pLook_{i-1}*(1 - pBreak)*(1 - pRel_{i-1})$\n",
    "\n",
    "$pFound = \\sum_{i=1}^{N}pLook_i*pRel_i$\n",
    "\n",
    "Implement `pFound` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pFound(search_results, relevance):    \n",
    "    # Constants\n",
    "    pBreak = 0.15\n",
    "    pRel = 0.4\n",
    "    \n",
    "    result = 0\n",
    "    for id, search_result in enumerate(search_results):\n",
    "        # Save all relevant docs id into set\n",
    "        relevant_ids = set([r[0] for r in relevance[id + 1]])\n",
    "        \n",
    "        # Calculate relevance for each doc\n",
    "        # pRel by default for a relevan document, otherwise 0\n",
    "        pRels = [pRel if doc_id in relevant_ids else 0 for doc_id in search_result]\n",
    "        \n",
    "        # pLook for the first element is 1.\n",
    "        # Others pLook's will be calculated later\n",
    "        pLook = [1] + [0] * (len(search_result) - 1)\n",
    "        \n",
    "        # Calculate pLook for the current search result docs\n",
    "        for i in range(1, len(search_result)):          \n",
    "            pLook[i] = pLook[i - 1] * (1 - pRels[i - 1]) * (1 - pBreak)\n",
    "        \n",
    "        # Calculate pFound for the current search result\n",
    "        pFound = 0\n",
    "        for i in range(len(search_result)):\n",
    "            pFound += pLook[i] * pRels[i]\n",
    "        \n",
    "        result += pFound\n",
    "\n",
    "    return result / len(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pFound 0.5821558180674999\n"
     ]
    }
   ],
   "source": [
    "pFound_test = pFound(test_results, test_relevance)\n",
    "print(\"pFound\", pFound_test)\n",
    "assert np.isclose(pFound_test, 0.582, atol=1e-03)\n",
    "assert pFound(test_results[:5], test_relevance) > pFound(test_results[5:10], test_relevance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
